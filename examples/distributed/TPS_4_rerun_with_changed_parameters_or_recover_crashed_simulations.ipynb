{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massively parallel Transition Path Sampling\n",
    "\n",
    "## Notebook 4: Rerun TPS simulation with changed parameters/Recover crashed simulations\n",
    "\n",
    "This is the fourth of a series of example notebooks on massively parallel transition path sampling. Here you will learn how you can rerun a TPS simulation from the folder structure and files on disk (possibly changing the reaction coordinate model architecture and/or `descriptor_transform`). Note, that the same setup/logic can also be used to recover and continue a simulation that has incomplete Monte Carlo steps, either due to the machine it has been running on crashing or you terminating the simulation during runtime. In both cases we will use the `reinitialize_from_workdir` method, which will take care of adding all exisiting Monte Carlo steps to the new storage and then finish all partially finished trials. This will result in a brain object that has the same internal state as if it would have ran the simulation up to the current step and that can be used to continue the simulation.\n",
    "\n",
    "**This notebook should be run on a multi-core workstation preferably with a GPU**, otherwise you will have a very long coffee break and a very hot laptop.\n",
    "\n",
    "**Required knowledge/recommended reading:** This notebooks assumes some familarity with the `asyncmd` (namely the [gromacs] engine and TrajectoryFunctionWrapper classes). Please see the example notebooks in `asyncmd` for an introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_dev/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n",
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import MDAnalysis as mda\n",
    "# asyncmd for the engine and Trajectory class\n",
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx\n",
    "from asyncmd import Trajectory\n",
    "# aimmd for the TPS\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd\n",
    "# and pytorch for the reaction coordinate model\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "scratch_dir = \".\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"TransitionPathSampling_ala\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinitialize the TPS simulation from state on disk\n",
    "\n",
    "To reinitialize the TPS we need to create a fresh brain object using the usual ingridients, just that this time we must take care for many things to set them to the same values as in the initial simulation we are reinitializing:\n",
    " - We must set the number of markov chain Markov chain samplers to the number we used previously\n",
    " - We must create a new storage file to save our models, trainset and other simulation results\n",
    " - We must use the same metastable state definition as previously (otherwise we will break the Markov chain by changing the length of the transitions and potentially changing the state assignment of endstates)\n",
    " - We must define the underlying dynamics the be the same as in the previous simulation, i.e. we can only change engine options that do not change the propagator $p(x_{t + \\Delta t} | x_{t}, \\Delta t)$ (where $x_{t}$ is a phase space point on a trajectory at time $t$). That means we can not change the forcefield, temperature and pressure coupling, and many more, but we should be able to change engine options like the number of threads and many more to e.g. optimize efficiency on changed hardware.\n",
    " - There is no need to load the old initial transitions, except if you (like we do here) want to get the dimensionality of your `descriptor_transform` by applying it to them.\n",
    " - You can change both the `descriptor_transform` and the reaction coordinate model architecture. Note however, that the Markov chain acceptances in the chain will be unchanged (i.e. calculated by the old model) up to the last previously finished step.\n",
    " - You must define the same sampling scheme, i.e. use the same number of movers and corresponding probabilities.\n",
    " - You should create a new trainset into which we will add the simulation results (shooting outcomes) including the ones found on disk.\n",
    " - You can define different `Task`s to run after specified number of trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samplers = 5  # results in 2*n_samplers gmx engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create storage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = aimmd.Storage(os.path.join(workdir, \"new_storage.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State definition\n",
    "\n",
    "We must use the same `alpha_R` and `C7_eq` state definitions as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state functions\n",
    "from state_funcs_mda import alpha_R, C7_eq\n",
    "\n",
    "wrapped_alphaR = asyncmd.trajectory.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "wrapped_C7_eq = asyncmd.trajectory.PyTrajectoryFunctionWrapper(C7_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underlying dynamics\n",
    "\n",
    "Again, make sure you are not changing the propagator properties, we will just use the same options as in the notebooks before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine(s) for the PathMovers\n",
    "# (they will all be the same)\n",
    "gro = \"gmx_infiles/conf.gro\"\n",
    "top = \"gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"gmx_infiles/index.ndx\"\n",
    "mdp = asyncgmx.MDP(\"gmx_infiles/md.mdp\")\n",
    "\n",
    "gmx_engine_kwargs = {\"mdconfig\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"output_traj_type\": \"XTC\",\n",
    "                     #\"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     \"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = asyncgmx.GmxEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reaction coordinate model and `descriptor_transform`\n",
    "\n",
    "Here we will use `descriptor_func_psi_phi` now instead of the full internal coordinate representation this function only returns the $\\psi$ and $\\phi$ dihedral angles (which are a decent representation but not fully informative, so you might see a drop in prediction quality if you continue to run the TPS simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import descriptor_transform for the model\n",
    "# descriptor_func_ic gives us an internal coordinate representation (i.e. bond lengths, angles and dihedrals)\n",
    "# descriptor_func_psi_phi gives us the ψ and φ dihedral angles (we use it to project to a 2d space in which we can look at the TPE)\n",
    "from state_funcs_mda import descriptor_func_ic, descriptor_func_psi_phi\n",
    "\n",
    "# and as usual wrapp them to become awaitable\n",
    "wrapped_transform = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_ic, call_kwargs={\"molecule_selection\": \"protein\"})\n",
    "wrapped_psi_phi = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_psi_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit 1 is 2 units wide.\n",
      "ResUnit 2 is 2 units wide.\n",
      "ResUnit 3 is 2 units wide.\n",
      "ResUnit 4 is 2 units wide.\n",
      "ResUnit 5 is 2 units wide.\n"
     ]
    }
   ],
   "source": [
    "# model architecture definition\n",
    "# we use a pyramidal ResNet as described in \"Machine-guided path sampling to discover mechanisms of molecular self-organization\" (Nat.Comput.Sci 2023)\n",
    "# Note that now this is not pyramidal anymore as we only have 2 inputs, it is just n_lay_pyramid of resunits stacked ontop of each other\n",
    "\n",
    "n_lay_pyramid = 5  # number of resunits\n",
    "n_unit_top = 2  # number of units in the last layer before the log_predictor\n",
    "n_unit_base = cv_ndim = 2 # descriptors_for_tp.shape[1]  # input dimension\n",
    "# the factor by which we reduce the number of units per layer (the width) and the dropout fraction\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "# create a list of modules to build our pytorch reaction coodrinate model from\n",
    "modules = []\n",
    "\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i)))} units wide.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\n",
    "                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\n",
    "                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\n",
    "                                                 modules=modules,  # modules is a list of initialized torch.nn.Modules from arcd.pytorch.networks\n",
    "                                                 )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "\n",
    "# choose and initialize an optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapp the pytorch neural network model in a RCModel class\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,  \n",
    "                                                            'lr_min': 5e-5,  # lr_min = lr_0 / 20 is a good choice empirically\n",
    "                                                            'epochs_per_train': 3,\n",
    "                                                            'window': 100,\n",
    "                                                            'batch_size': 8192,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_psi_phi,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the sampling scheme\n",
    "\n",
    "We use the same sampling scheme as in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spselector = aimmdd.spselectors.RCModelSPSelectorFromTraj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  # NOTE: we could chnage the walltime per part, this could e.g. optimize queueing times  \n",
    "                  #'walltime_per_part': 0.000015625,  # 0.055125 s per part\n",
    "                  'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  #'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  #'walltime_per_part': 0.000125,  # 0.45 s per part\n",
    "                  #'walltime_per_part': 0.001,  # 3.6 s per part\n",
    "                  #'walltime_per_part': 0.004,  # 14.4 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": spselector,  # use the spselctor we have defined above \n",
    "                  \"max_steps\": 500 * 10**5,  # 500 steps * dt (2 fs) = 1 ps\n",
    "                  }\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainset\n",
    "\n",
    "We intiialize an empty trainset, but we could also use one that already contains shooting results. Just be careful with the results from the simulation we are reinitializing, otherwise they will be in there twice (at least if we use `reinitialize_from_workdir` with `run_tasks=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain tasks\n",
    "\n",
    "We will use the same Tasks as in the notebooks before, but you could e.g. change the run intervals or saving intervals of certain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "    aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset),\n",
    "    aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                              first_collection=100,\n",
    "                                              recreate_interval=250,\n",
    "                                              ),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and initialize the brain as before\n",
    "brain = aimmdd.Brain.samplers_from_moverlist(model=model, workdir=workdir, storage=storage,\n",
    "                                             n_sampler=n_samplers,\n",
    "                                             movers_cls=movers_cls, movers_kwargs=movers_kwargs,\n",
    "                                             samplers_use_same_stepcollection=False,\n",
    "                                             tasks=tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinitialize the brain from workdir\n",
    "\n",
    "The coroutine `reinitialize_from_workdir` adds all previously finished trials to the new storage and brain. If we call it with `run_tasks=True` (the default) it will also run all of its attached tasks for those trials in the order they finished. This will add the trials to the trainingset and train the model as if it would have steered this simulation itself (except that it did not select the SPs, but it will still predict for them before observing the result and be trained according to its prediction quality). After adding all finished trials the coroutine will check for any unfinished trials and finish them. After that you can continue the simulation with the brain object and potentialy a new reaction coordinate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding all finished steps we have a total of 10018 steps. Note that potential unfinished steps will only be finished when calling `Brain.run_for_n_steps()` or Brain.run_for_n_accepts()`.\n"
     ]
    }
   ],
   "source": [
    "await brain.reinitialize_from_workdir(run_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10018"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue the TPS simulation\n",
    "\n",
    "We can now continue the TPS simulation as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 100 cummulative MCSteps took 107.79982328414917 s (= 1.796663721402486 min).\n"
     ]
    }
   ],
   "source": [
    "n_steps = 100\n",
    "start = time.time()\n",
    "\n",
    "await brain.run_for_n_steps(n_steps)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Running for {n_steps} cummulative MCSteps took {end-start} s (= {(end-start)/60} min).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10118"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the last model, trainset and brain to storage\n",
    "As usual, save the last model, trainset and brain. Then close the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.rcmodels[\"model_to_continue_with\"] = model\n",
    "storage.save_trainset(trainset)\n",
    "storage.save_brain(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
