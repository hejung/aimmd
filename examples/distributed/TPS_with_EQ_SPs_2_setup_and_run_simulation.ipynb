{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massively parallel ML assisted transition path sampling from equilibrium shooting points\n",
    "\n",
    "## Notebook 2: Setup and run TPS simulation\n",
    "\n",
    "This is the second of a series of example notebooks on massively parallel transition path sampling (TPS) using shooting points with a known equilibrium weight. If you have not done so, please have a look at and run the first notebook of the series, it must be run before this one.\n",
    "\n",
    "In this notebook we will perform the actual TPS simulation. We will use the locally running `GmxEngine` and `PyTrajectoryFunctionWrapper` classes (such that you can run it on your workstation), but you can easily perform a massively parallel TPS on a HPC cluster running SLURM by using the `SlurmGmxEngine` and `SlurmTrajectoryFunctionWrapper` classes instead. However, in that case you will probably want to use a larger (and more interessting) system than capped alanine dipeptide :)\n",
    "\n",
    "**This notebook should be run on a multi-core workstation preferably with a GPU**, otherwise you will have a very long coffee break and a very hot laptop.\n",
    "\n",
    "**Required knowledge/recommended reading:** This notebooks assumes some familarity with the `asyncmd` (namely the [gromacs] engine and TrajectoryFunctionWrapper classes). Please see the example notebooks in `asyncmd` for an introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_dev/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n",
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import MDAnalysis as mda\n",
    "# need asyncmd for the engine and trajectory classes\n",
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx\n",
    "from asyncmd import Trajectory\n",
    "# and aimmd for the TPS\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd\n",
    "# and some imports for the model\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "scratch_dir = \".\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"TransitionPathSampling_with_EQ_SPs_ala\")\n",
    "\n",
    "if not os.path.isdir(workdir):\n",
    "    os.mkdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logging to a file (optional)\n",
    "\n",
    "The next few cells are just to show you how to configure pythons logging module to write to a logfile in the directory where we do the simulation. It is not necessary to run aimmd but it might be helpful to find out what went wrong if something does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# executing this file sets the variable LOGCONFIG, which is a dictionary of logging presets \n",
    "%run ../resources/logconf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 'WARN', 'handlers': ['stdf', 'warnout']}\n",
      "{'level': 'INFO'}\n",
      "{'class': 'logging.FileHandler', 'level': 'INFO', 'mode': 'w', 'filename': 'simulation.log', 'formatter': 'standardFormatter'}\n"
     ]
    }
   ],
   "source": [
    "# have a look at the default logging level (the level used for the root logger)\n",
    "print(LOGCONFIG[\"loggers\"][\"\"])\n",
    "# have a look at the logger for aimmd\n",
    "print(LOGCONFIG[\"loggers\"][\"aimmd\"])\n",
    "# and have a look at the log-level for the filehandler\n",
    "print(LOGCONFIG[\"handlers\"][\"stdf\"])\n",
    "# the last two should both be `INFO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: more logging to file\n",
    "level = \"INFO\"\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"level\"] = level\n",
    "LOGCONFIG[\"loggers\"][\"aimmd\"][\"level\"] = level\n",
    "LOGCONFIG[\"loggers\"][\"asyncmd\"] = {\"level\": level}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can either modify single values or use it as is to get the same setup as in the OPS default logging config file\n",
    "# you could e.g. do LOGCONF['handlers']['stdf']['filename'] = new_name to change the filename of the log\n",
    "# the default is to create 'simulation.log' and 'initialization.log' in the current working directory\n",
    "import logging.config\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"filename\"] = os.path.join(workdir, \"simulation_pathsampling.log\")\n",
    "LOGCONFIG[\"handlers\"][\"initf\"][\"filename\"] = os.path.join(workdir, \"initlog_pathsampling.log\")\n",
    "logging.config.dictConfig(LOGCONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the TPS simulation\n",
    "\n",
    "To setup the TPS simulation we need the following prerequistes:\n",
    " \n",
    " - Decide how many samplers we will run in parallel. The samplers are the objects/class that take care of the actual trial generation, i.e. using a larger number here means more parallel workload but shorter time to result as long as you are not resource limited (because the trial generation trivialy parallelizes).\n",
    " - Create a storage file so we can save our results and trained reaction coordinate models.\n",
    " - Define the metastable states (such that we know when to stop the intergation).\n",
    " - Define the underlying dynamics (by defining a gromacs engine and its parameters).\n",
    " - Define the set of shooting points and calculate their respective equilibrium weights (we will use the configurations from the umbrella sampling in the previous notebook).\n",
    " - Define the reaction coordinate model and the space it is learning in by choosing the `descriptor_transform` (which transforms from configurations to descriptor space)\n",
    " - Define the sampling scheme, i.e. how we generate new trials (here we will use two way shooting moves with random velocities).\n",
    " - Create a trainset into which we will add the simulation results (shooting outcomes).\n",
    " - Define the `Task`s to run after a specified number of trials. These are used to e.g. train the reaction coordinate model or save the trainset, model and brain at specified intervals. They are similar to the openpathsampling concept of hooks.\n",
    "\n",
    "Then we finally put everything together and initialize a `Brain` with the defined variables. The `Brain` is the central object to interact with when running the TPS simulation according to your setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samplers = 5  # results in 2*n_samplers gmx engines running in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create storage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a storage file for our simulation results and reaction coordinate models\n",
    "storage = aimmd.Storage(os.path.join(workdir, \"storage.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import state functions\n",
    "# these are python function returning True/False for every frame on a trajectory depending on if the frame is in the respective state\n",
    "# they are defined in the file state_funcs_mda.py, you might want to have a look at it when writing your own state functions\n",
    "# we will also directly import descriptor_func_psi_phi to calculate the weights below\n",
    "# descriptor_func_psi_phi gives us the ψ and φ dihedral angles (we use it to project to a 2d space in which we can look at the TPE)\n",
    "from state_funcs_mda import alpha_R, C7_eq, descriptor_func_psi_phi\n",
    "\n",
    "# wrapp the state functions to make them awaitable\n",
    "# (if you want to learn more about the TrajectoryFunctionWrappers have a look at the asyncmd example notebooks)\n",
    "wrapped_alphaR = asyncmd.trajectory.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "wrapped_C7_eq = asyncmd.trajectory.PyTrajectoryFunctionWrapper(C7_eq)\n",
    "wrapped_psi_phi = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_psi_phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underlying dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine(s) for the PathMovers\n",
    "# (they will all be the same, so we define it only once)\n",
    "gro = \"gmx_infiles/conf.gro\"\n",
    "top = \"gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"gmx_infiles/index.ndx\"\n",
    "mdp = asyncgmx.MDP(\"gmx_infiles/md.mdp\")\n",
    "\n",
    "gmx_engine_kwargs = {\"mdconfig\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"output_traj_type\": \"XTC\",\n",
    "                     #\"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     \"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = asyncgmx.GmxEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shooting points and their equilibrium weights\n",
    "\n",
    "Here we will use the configurations from the one umbrella window in the first notebook. This enables us to calculate equilibrium weights as $\\exp(\\beta V_{bias})$. We could naturaly instead use configurations from multiple differnt biasing potentials and would then obtain the equilibrium weights from running (binless) WHAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the US trajectory and calculate weights for reweighting to eq\n",
    "path_to_us = os.path.join(scratch_dir, \"UmbrellaSampling\")\n",
    "\n",
    "us_traj = asyncmd.Trajectory(structure_file=os.path.join(path_to_us, \"US.tpr\"),\n",
    "                             trajectory_files=os.path.join(path_to_us, \"US.part0001.xtc\"))\n",
    "us_mdp = asyncgmx.MDP(os.path.join(path_to_us, \"US.mdp\"))\n",
    "\n",
    "psi_phi_us = await wrapped_psi_phi(us_traj)\n",
    "\n",
    "# now calculate the weights\n",
    "from scipy import constants\n",
    "\n",
    "# read the values for force constant and potential zero point directly from the umbrella sampling mdp\n",
    "T = us_mdp[\"ref-t\"][0]\n",
    "k_psi = us_mdp[\"pull-coord1-k\"] # kJ/ (mol * rad**2)\n",
    "psi_0 = us_mdp[\"pull-coord1-init\"] * np.pi / 180  # psi_0 in rad\n",
    "try:\n",
    "    # make sure we do not crash if we biased only along ψ (and not also along φ)\n",
    "    k_phi = us_mdp[\"pull-coord2-k\"] # kJ/ (mol * rad**2)\n",
    "    phi_0 = us_mdp[\"pull-coord2-init\"] * np.pi / 180  # psi_0 in rad\n",
    "except KeyError:\n",
    "    k_phi = 0\n",
    "    phi_0 = 0\n",
    "\n",
    "# Note that gromacs uses the conventions:\n",
    "#      U_bias = k/2 (x - x0)**2\n",
    "#      F_bias = - k (x - x0)\n",
    "\n",
    "def U_bias(x, x_0, k):\n",
    "    return (k / 2.) * (x - x_0) * (x - x_0)\n",
    "\n",
    "beta = 1000 / (constants.R * T)  # beta in kJ /mol\n",
    "\n",
    "# we have just one umbrella window, the weights for the structures are just exp(\\beta V_{bias})\n",
    "# (as these are the weights one would use to get out the Boltzmann distribution on the original PES) \n",
    "weights = np.exp(beta * ( U_bias(psi_phi_us[:, 0], psi_0, k_psi) + U_bias(psi_phi_us[:, 1], phi_0, k_phi) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# have a look at the histogram of weights to check that they are not too different\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "axs.hist(weights, bins=200);\n",
    "axs.set_xscale(\"log\")\n",
    "axs.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaction coordinate model and `descriptor_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import descriptor_transform for the model\n",
    "# descriptor_func_ic gives us an internal coordinate representation (i.e. bond lengths, angles and dihedrals)\n",
    "from state_funcs_mda import descriptor_func_ic, descriptor_func_psi_phi\n",
    "\n",
    "# and as usual wrapp them to become awaitable\n",
    "wrapped_transform = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_ic, call_kwargs={\"molecule_selection\": \"protein\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the descriptors for the umbrella sampling trajectory\n",
    "# (we do this to get the dimension of the descriptors to know the input dimension of our model)\n",
    "descriptors_for_us = await wrapped_transform(us_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit 1 is 66 units wide.\n",
      "Dropout before it is 0.18674307214231128.\n",
      "ResUnit 2 is 41 units wide.\n",
      "Dropout before it is 0.1162432499771616.\n",
      "ResUnit 3 is 25 units wide.\n",
      "Dropout before it is 0.07235873872180604.\n",
      "ResUnit 4 is 16 units wide.\n",
      "Dropout before it is 0.045041643884176266.\n",
      "ResUnit 5 is 10 units wide.\n",
      "Dropout before it is 0.02803738317757008.\n"
     ]
    }
   ],
   "source": [
    "# model architecture definition\n",
    "# we use a pyramidal ResNet as described in \"Machine-guided path sampling to discover mechanisms of molecular self-organization\" (Nat.Comput.Sci 2023)\n",
    "\n",
    "n_lay_pyramid = 5  # number of resunits\n",
    "n_unit_top = 10  # number of units in the last layer before the log_predictor\n",
    "dropout_base = 0.3  # dropot fraction in the first layer (will be reduced going to the top)\n",
    "n_unit_base = cv_ndim = descriptors_for_us.shape[1]  # input dimension\n",
    "# the factor by which we reduce the number of units per layer (the width) and the dropout fraction\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "# create a list of modules to build our pytorch reaction coodrinate model from\n",
    "modules = []\n",
    "\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    modules += [aimmd.pytorch.networks.FFNet(n_in=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                             n_hidden=[max(n_unit_top, int(n_unit_base * fact**i))],  # 1 hidden layer network\n",
    "                                             activation=torch.nn.Identity(),\n",
    "                                             dropout={\"0\": dropout_base * fact**i}\n",
    "                                             )\n",
    "                ]\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i)))} units wide.\")\n",
    "    print(f\"Dropout before it is {dropout_base * fact**i}.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "\n",
    "# and build the reaction coodrinate model\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\n",
    "                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\n",
    "                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\n",
    "                                                 modules=modules,  # modules is a list of initialized torch.nn.Modules from arcd.pytorch.networks\n",
    "                                                 )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "\n",
    "# finaly choose and initialize an optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapp the pytorch neural network model in a RCModel class,\n",
    "# these classes know how to decide if they should train in a self-consistent way\n",
    "# and they also know how to transform from configurations to descriptors space (because they know about the descriptor_transform) \n",
    "# Here we take an ExpectedEfficiencyPytorchRCModel,\n",
    "# this RCmodel scales the learning rate by the expected efficiency factor (1 - n_TP_true / n_TP_expected)**2\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,  \n",
    "                                                            'lr_min': 5e-5,  # lr_min = lr_0 / 20 is a good choice empirically\n",
    "                                                            'epochs_per_train': 3,\n",
    "                                                            'interval': 5,\n",
    "                                                            'window': 100,\n",
    "                                                            'batch_size': 8192,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_transform,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the sampling scheme\n",
    "\n",
    "We will first define the shooting point selection, usualy the shooting point selector (or equivalently the choosen selection scheme) determines the acceptance probability for each new trial. Here the shooting point selector determines the weight for each newly generated transition since we are doing TPS from equilibrium shooting points.\n",
    "\n",
    "We will then use the selector to setup our sampling scheme, which is very simple here as it only consists of one mover (the two way shooting mover). However you can use an arbitray number of movers (potentially defining a probability for each of them), in that case each mover will be picked with the given probability to generate the next trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the SP selector object\n",
    "# it needs the configurations to slect SPs from as asyncmd trajectories and the respective equilibrium weights\n",
    "# density_adaption decides if we should correct for the density of SPs projected into committor space when picking configurations\n",
    "selector = aimmdd.spselectors.RCModelSPSelectorFromEQ(trajectories=us_traj, equilibrium_weights=weights, density_adaptation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a list of movers\n",
    "# since we want to create n_sampler identical samplers it is easiest to use the `Brain.samplers_from_moverlist()` function\n",
    "# This function will create n_sampler identical PathChainSamplers where the movers for each sampler are\n",
    "# specified by movers_cls (a list of mover classes) and movers_kwargs (a dict with keyword arguments used for initialization of the movers)\n",
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  # NOTE: choose this as short as possible!\n",
    "                  #       since ala is super-small and commits fast we should make sure\n",
    "                  #       that most trials reach a state in the first part\n",
    "                  #       this in turn makes sure that we do not call gromacs multiple times per trial (saving setup time)\n",
    "                  #       but still ensures that the resulting trajectories are not too long and large\n",
    "                  #       it also reduces the time needed per step (we need at least walltime_per_part hours per step)\n",
    "                  #'walltime_per_part': 0.000015625,  # 0.055125 s per part\n",
    "                  'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  #'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  #'walltime_per_part': 0.000125,  # 0.45 s per part\n",
    "                  #'walltime_per_part': 0.001,  # 3.6 s per part\n",
    "                  #'walltime_per_part': 0.004,  # 14.4 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": selector,  # use the SP selector from the cell above \n",
    "                  \"max_steps\": 500 * 10**5,  # 500 steps * dt (2 fs) = 1 ps\n",
    "                  }\n",
    "                 ]\n",
    "\n",
    "# Note that for full flexibility of the sampling scheme setup we could also use a list of lists with initialized movers\n",
    "# then however we need the outermost list to be of length n_sampler as shown below\n",
    "#movers = [[aimmdd.TwoWayShootingPathMover(states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "#                                          engine_cls=gmx_engine_cls,\n",
    "#                                          engine_kwargs=gmx_engine_kwargs,\n",
    "#                                          engine_config=mdp,\n",
    "#                                          walltime_per_part=0.00003125,\n",
    "#                                          T=mdp[\"ref-t\"][0],\n",
    "#                                          sp_selector=selector,\n",
    "#                                          max_steps=500 * 10**5,\n",
    "#                                         )\n",
    "#           ] for i in range(n_samplers)\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain tasks\n",
    "\n",
    "Each task will be run after every finished Monte Carlo step with the step and the index of the sampler it came from as arguments. You can also define your own tasks to modify the behaviour of the TPS simulation easily (openpathsampling users should think of hooks). Note that each user defined Task should subclass `aimmd.distributed.pathsampling.BrainTask`. Note also that the tasks will be run in the order that they are in the list, i.e. for the list below the `TrainingTask` will be run first and the `DensityCollectionTask` will run last for every Monte Carlo step.\n",
    "\n",
    "A number of required and (potentially) useful Tasks are already included with `aimmd.distributed`, e.g. the `TrainingTask` (which adds new shooting results to the training set and perdiodically asks the reaction coordinate model to train), the `SaveTask` (which saves the reaction coordinate model and training set periodically), and the `DensityCollectionTask` (which regularly updates the estimate of the density of shooting points projected to committor space) will be an integral part of most/all TPS simulations.\n",
    "\n",
    "A noteworthy Task class for longrunning TPS simulations is the `StorageCheckpointTask` which creates a copy of the `aimmd.Storage` used during the simulation at a given interval of finished Monte Carlo steps. The copy of the storage file can then be openend and accessed while the TPS simulation is still running, thereby enabeling preliminary analyses of a long-running TPS simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    # the TrainingTask takes care of training the model (or better: reminding the model to decide if it wants to train)\n",
    "    aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "    # the SaveTask saves the model, trainset and brain to storage at specified interval during the simulation\n",
    "    aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset,\n",
    "                                 # leave saving interval at its default\n",
    "                                 interval=100,\n",
    "                                 # and also the savename prefix for the models\n",
    "                                 name_prefix=\"Central_RCModel\",\n",
    "                                 ),\n",
    "    # the DensityCollectionTask takes care of updating the estimate of the density of shooting points\n",
    "    # projected into committor space\n",
    "    # It needs to know what the ensemble is we shoot from (e.g. \"custom\" for a self-defined set of shooting points\n",
    "    #  or \"p_x_TP\" if we shoot from previous transitions)\n",
    "    aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                              first_collection=0,\n",
    "                                              recreate_interval=50,\n",
    "                                              mode=\"custom\",\n",
    "                                              trajectories=[us_traj],\n",
    "                                              trajectory_weights=[weights],\n",
    "                                              ),\n",
    "    # the StorageCheckpointTask is commented out because this simulation should not run soo long\n",
    "    #aimmdd.pathsampling.StorageCheckpointTask(storage=storage,  # the storage to checkpoint\n",
    "    #                                          # increase the checkpoint interval to 100 MCSteps\n",
    "    #                                          interval=100,\n",
    "    #                                          # and leave the options that control the checkpoint\n",
    "    #                                          # naming at their default values\n",
    "    #                                          checkpoint_suffix=\".ckpt\",\n",
    "    #                                          checkpoint_prev_suffix=\"_prev\",\n",
    "    #                                          )\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the 'easy' way to setup n_sampler identical samplers (using `samplers_from_moverlist` as promised above)\n",
    "brain = aimmdd.Brain.samplers_from_moverlist(model=model, workdir=workdir, storage=storage,\n",
    "                                             n_sampler=n_samplers,\n",
    "                                             movers_cls=movers_cls, movers_kwargs=movers_kwargs,\n",
    "                                             samplers_use_same_stepcollection=True,\n",
    "                                             tasks=tasks)\n",
    "                                             # Note that we left mover_weights=None at its default, this results\n",
    "                                             # in uniform weights for all movers\n",
    "\n",
    "# and this would be the full __init__ call to the brain (given you defined `movers` as above commented out) \n",
    "# it gives you full flexibility of setting up every PathChainSampler individually\n",
    "#brain = aimmdd.Brain(model=model, workdir=workdir, storage=storage, movers=movers, mover_weights=[[1.], [1.], [1.]], tasks=tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Depending on your transition path sampling scheme you would need to now provide initial transitions to initialize the TPS, however here since we shoot from an ensemble of shooting points we can just start the TPS (and ignore the warnings below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the TPS simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see how long it runs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(WARNING)aimmd.distributed.pathsampling make_step: Sampler 0: Instep is None. This will only work with sampling schemes that generate their own shooting points.\n",
      "(WARNING)aimmd.distributed.pathsampling make_step: Sampler 1: Instep is None. This will only work with sampling schemes that generate their own shooting points.\n",
      "(WARNING)aimmd.distributed.pathsampling make_step: Sampler 2: Instep is None. This will only work with sampling schemes that generate their own shooting points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation at Fri Jul 26 14:28:39 2024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(WARNING)aimmd.distributed.pathsampling make_step: Sampler 3: Instep is None. This will only work with sampling schemes that generate their own shooting points.\n",
      "(WARNING)aimmd.distributed.pathsampling make_step: Sampler 4: Instep is None. This will only work with sampling schemes that generate their own shooting points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 26 14:36:00 2024: 500 (of 10000) steps done. Produced 500 new accepts so far. Estimated end time is Fri Jul 26 16:55:22 2024.\n",
      "Fri Jul 26 14:43:42 2024: 1000 (of 10000) steps done. Produced 1000 new accepts so far. Estimated end time is Fri Jul 26 16:59:08 2024.\n",
      "Fri Jul 26 14:51:43 2024: 1500 (of 10000) steps done. Produced 1500 new accepts so far. Estimated end time is Fri Jul 26 17:02:26 2024.\n",
      "Fri Jul 26 14:59:47 2024: 2000 (of 10000) steps done. Produced 2000 new accepts so far. Estimated end time is Fri Jul 26 17:04:18 2024.\n",
      "Fri Jul 26 15:08:11 2024: 2500 (of 10000) steps done. Produced 2500 new accepts so far. Estimated end time is Fri Jul 26 17:06:46 2024.\n",
      "Fri Jul 26 15:16:43 2024: 3000 (of 10000) steps done. Produced 3000 new accepts so far. Estimated end time is Fri Jul 26 17:08:53 2024.\n",
      "Fri Jul 26 15:25:27 2024: 3500 (of 10000) steps done. Produced 3500 new accepts so far. Estimated end time is Fri Jul 26 17:10:57 2024.\n",
      "Fri Jul 26 15:34:52 2024: 4000 (of 10000) steps done. Produced 4000 new accepts so far. Estimated end time is Fri Jul 26 17:14:11 2024.\n",
      "Fri Jul 26 15:44:17 2024: 4500 (of 10000) steps done. Produced 4500 new accepts so far. Estimated end time is Fri Jul 26 17:16:44 2024.\n",
      "Fri Jul 26 15:53:34 2024: 5000 (of 10000) steps done. Produced 5000 new accepts so far. Estimated end time is Fri Jul 26 17:18:28 2024.\n",
      "Fri Jul 26 16:03:18 2024: 5500 (of 10000) steps done. Produced 5500 new accepts so far. Estimated end time is Fri Jul 26 17:20:45 2024.\n",
      "Fri Jul 26 16:13:03 2024: 6000 (of 10000) steps done. Produced 6000 new accepts so far. Estimated end time is Fri Jul 26 17:22:38 2024.\n",
      "Fri Jul 26 16:22:45 2024: 6500 (of 10000) steps done. Produced 6500 new accepts so far. Estimated end time is Fri Jul 26 17:24:10 2024.\n",
      "Fri Jul 26 16:32:42 2024: 7000 (of 10000) steps done. Produced 7000 new accepts so far. Estimated end time is Fri Jul 26 17:25:51 2024.\n",
      "Fri Jul 26 16:42:30 2024: 7500 (of 10000) steps done. Produced 7500 new accepts so far. Estimated end time is Fri Jul 26 17:27:06 2024.\n",
      "Fri Jul 26 16:52:32 2024: 8000 (of 10000) steps done. Produced 8000 new accepts so far. Estimated end time is Fri Jul 26 17:28:30 2024.\n",
      "Fri Jul 26 17:02:43 2024: 8500 (of 10000) steps done. Produced 8500 new accepts so far. Estimated end time is Fri Jul 26 17:29:54 2024.\n",
      "Fri Jul 26 17:13:02 2024: 9000 (of 10000) steps done. Produced 9000 new accepts so far. Estimated end time is Fri Jul 26 17:31:18 2024.\n",
      "Fri Jul 26 17:23:56 2024: 9500 (of 10000) steps done. Produced 9500 new accepts so far. Estimated end time is Fri Jul 26 17:33:09 2024.\n",
      "Fri Jul 26 17:34:27 2024: 10000 (of 10000) steps done. Produced 10000 new accepts so far. Estimated end time is Fri Jul 26 17:34:27 2024.\n",
      "Running for 10000 cummulative MCSteps took 11147.851045131683 s (= 185.7975174188614 min).\n"
     ]
    }
   ],
   "source": [
    "n_steps = 10000\n",
    "start = time.time()\n",
    "\n",
    "await brain.run_for_n_steps(n_steps,\n",
    "                            print_progress=500,  # print a short progress summary every 500 steps\n",
    "                            )\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Running for {n_steps} cummulative MCSteps took {end-start} s (= {(end-start)/60} min).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the last model, trainset and brain to storage\n",
    "This enables us to do the analysis in a different notebook or continue the TPS simulation from the last step easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the last model\n",
    "storage.rcmodels[\"model_to_continue_with\"] = model\n",
    "storage.save_trainset(trainset)  # the trainset\n",
    "storage.save_brain(brain)  # and the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly close the storage to make sure all writes are complete\n",
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
